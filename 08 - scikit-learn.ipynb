{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIKIT-LEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data-Science eco-system of Python packages is large. A couple of the other popular ones:\n",
    "* Statsmodels: supporting a wide range of regression (GLM, GAM, ...) and timeseries models\n",
    "* SciPy: a more low-level tool for scientific computation\n",
    "* TensorFlow: Neural Network package by Google\n",
    "* PyTorch: Nearal Network package by Facebook\n",
    "* Keras: a high-level interface to creae nn-architectures\n",
    "* PyMC3: Bayesian modelling\n",
    "* CVX: convex optimization\n",
    "* SpaCy: natural language processing library\n",
    "* transformers: a library & collection of transformer models, using the hugely powerfull transformer nn architecture for NLP\n",
    "* ...\n",
    "\n",
    "**scikit-learn** (aka **sklearn**) is probably one of the most accessible & popular Machine Learning library in Python.<br>\n",
    "It offers a rich set of models, and a very elegant & user-friendly API covering the complete data-science workflow.<br>\n",
    "If you could master one Machine Learning toolkit in Python, scikit-learn would probably be it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some background:<br>\n",
    "\n",
    "The scikit-learn project **was started in 2007** as a Google Summer of Code project by David Cournapeau.<br>\n",
    "Later that year, Matthieu Brucher started work on this project as part of his thesis.<br>\n",
    "\n",
    "In **2010** a group of developers in **INRIA** (National Institute for Research in Digital Science and Technology) took leadership of the project and made the first public release.<br>\n",
    "\n",
    "Since then, several releases have appeared following a ~ 3-month cycle, and a thriving international community has been leading the development.<br>\n",
    "\n",
    "Before we dive into the library, first a few remarks on Machine Learnig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical Modelling is …**<br>\n",
    "a *subfield of mathematics* which deals with finding relationship between random variables.<br><br>\n",
    "\n",
    "**Machine Learning is …**<br>\n",
    "a *subfield of computer science* which deals with building systems that can learn from data, instead of explicitly programmed instructions.<br><br>\n",
    "\n",
    "A different way of putting it: Machine Learning is the field of computer science build on top of statistics.<br>\n",
    "The focus is on implementations & frameworks enable exploring all possibilities afforded by modern hardware achitectures.<br>\n",
    "\n",
    "Contrary to statistics, where the focus is more on mathematical theory and reasoning with randomness / under uncertainty.<br>\n",
    "ML is IMHO a less theoretical persuit and has a strong focus on application.<br>\n",
    "\n",
    "In science an important objective is sparsity. To strip away all irrelevant detail and arrive at the a simplified desription of the world (a model) that is able to make accurate predictions in controlled experiments.<br>\n",
    "\n",
    "In typical Data Science settings, the objective is to predict / approximate as accurate as possible, **where sparsity and understanding are less of a concern**.<br>\n",
    "\n",
    "There are interesting discussions to be had regarding human bahaviour. Human bahaviour takes place in a messy world, instead of a highly controlled setting like in a scientific experiment. Therefore, the view of human learning as a messy feedback & adaptation process in a grosly overparameterized model (the typical human brain is has an estimated 100 trillion synapses) is probably very close tot he truth.<br>\n",
    "\n",
    "Anyhow, let's not get sidetracked to much at the start ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Complexity & Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model complexity, the complexity of the process generating the data, and the number of available observations all play an intricate role in statistical inference. Very roughly speaking: a complex model can only be trusted if the underlying process is complex and there is sufficient data available. When not enough data is available or the phenomenon is simpler than the model, it is called overfitting. A tell-tale sign is model predictions that are *too good to be true*.<br>\n",
    "\n",
    "As a simple example: $a * x_1 + b * x_2 = y$ and $(x_1, x_2, y) = (1, 1, 10)$, what is $a$?<br>\n",
    "From linear algebra we know that $n$ linear equations with $n-1$ unknowns will have a unique solution (if the $x$'s are independent)<br>\n",
    "So in the above case, when we would observe a second sample, we could always find a solution.<br>\n",
    "Stated differently, we can always find a line in 2D-space that perfectly fits 2 data points.\n",
    "<br>\n",
    "\n",
    "To *estimate* a population parameter (like $a$ & $b$), and indeed it's accuracy, we need many more observations than parameters.<br>\n",
    "The relationship between the accuracy of a population estimate and the number of observations,<br>\n",
    "is captured in the statistical concept of *degrees of freedom* (which goes to the hart of statistics).<br>\n",
    "\n",
    "The relevance of this concept breaks down when dealing with overparameterized models.<br>\n",
    "The model has many solutions which work well on our data & there is no way of telling which of those is most likely.<br>\n",
    "\n",
    "The advent of Machine Learnig, is driven by two important developments:\n",
    "* **computers** have become **much more powerfull**, resulting in **larger & more complex models**, helped by the fact that\n",
    "* the available **data has grown exponentially**\n",
    "\n",
    "The IDC forecasts the Global Datasphere to grow to 175 ZB by 2025 ... FYI: \n",
    "* One zettabyte = 10^21 bytes = 1000 exabytes = 1 million petabytes = 1 billion terabytes = 1 trillion gigabytes.\n",
    "* If you could download the entire 2025 Global Datasphere at an average of 25 Mb/s, it would take 1.8 billion years to do it (earth age estimated at ~4.5B years)\n",
    "\n",
    "### The ML way of dealing with overfitting & huge amounts of data\n",
    "1. split the data in:\n",
    "   * **train** dataset: used to train the model / estimate the model parameters.\n",
    "   * **test** dataset: a dataset to test the generalizability to data other than the train data.\n",
    "   * **validation** dataset: a dataset to test the validity of the final model on data that was never seen by the model.\n",
    "   Often in practice the data is split into *train* and *test* and the *validation* step is done on the test data.<br>\n",
    "   It is important to realize, that the the more data is used in the model selection process, the worse it will be at telling you how well the model generalizes.\n",
    "2. **k-fold cross-validation**: Insead of discarding data during training, the data gets split into k 'folds' (read a random split into k subgroups), and a model is fit k times, where each time a different fold is excluded from training and used for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Taxonomy 101: Supervised Learning v Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main categories:\n",
    "* **Supervised Learning**: where a known outcome is available. This outcome variable is often called the target.\n",
    "* **Unsupervised Learning**: where there is not a natural dependent variable, a value / label to be predicted.\n",
    "\n",
    "<img src=\"plots/ml_taxonomy.png\" width=\"700px\"><br>\n",
    "\n",
    "In addition to these two main categories, there are many subtle variations, like:\n",
    "* **semi-supervised** learning: where the outcome / label is only known for some of the training examples\n",
    "* **re-inforcement** learning: where the best response to some situation is learned in terms of maximizing some cumulative reward of actions / decisions (Typically represented as a Markov Decision Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where does scikit-learn fit in?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn sits between more statistically oriented packages like *stasmodels*, or *Py3MC* and the modern deep neural network libraries (TensorFlow, PyTorch, ...) that are IMHO black boxes with pre-cooked layer-architectures. scikit-learn offers a wealth of models & and a convenient & intuitive API to work with these models in modern data-science workflows.<br>\n",
    "\n",
    "It does not cover the use case of datasets that can no longer fit in memory (although extensions using DASK are available), or indeed models that no longer fit in memory. As an example of the latter, openAI has recently released it's GPT-3 language model containing 175 Billion parameters.<br>\n",
    "\n",
    "scikit-learn provides powerfull and (relatively) easy to use tools for problem-sizes that fit in memory in more capable systems,<br>\n",
    "the type of problem that typically occur in a company like Nationwide!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The scikit-learn API\n",
    "\n",
    "An API is an interface that allows the user to interact with a library.<br>\n",
    "It is basically a set of *interfaces* that allows you to call the functionality offered by the library.<br>\n",
    "\n",
    "A good API is:\n",
    "1. stable\n",
    "2. intuitive\n",
    "3. integrate with existing tools\n",
    "4. flexible\n",
    "\n",
    "scikit-learn is all of these. The breadth of tools it provides is overwelming.<br>\n",
    "But, like any good API, the way to use all this functionality is mostly intuitive and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "help(sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Typical Data Science Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. **load data**\n",
    "2. **pre-processing** & **feature enginering**, just to mention a few of the many 'transformaers' available:\n",
    "   * `sklearn.impute.SimpleImputer`: simple imputation using strategy: mean, median, most_frequent, constant\n",
    "   * `sklearn.feature_selection.SelectPercentile` : select % of features with 'best' uniform association, based on some measure.\n",
    "   * `sklearn.preprocessing.Normalizer`: normalization / scaling to unit norm, where norm: l1, l2, max, ...\n",
    "   * `sklearn.preprocessing.OneHotEncoder`: encoding categorical variables\n",
    "   * `sklearn.preprocessing.KBinsDiscretizer`: bin a numeric variable into discrete bins\n",
    "   * `sklearn.decomposition.PCA`: dimensionality reduction\n",
    "3. select, configure model and **fit** the model\n",
    "   * `fit` (aka train in the ML literature): find the parameter values that minimize some cost function, with optionally some regularization term\n",
    "4. model **evaluation** / selection --> maybe go back to (2)\n",
    "   * `sklearn.model_selection.confusion_matrix`\n",
    "   * `sklearn.model_selection.auc`\n",
    "   * `sklearn.model_selection.roc_curve`\n",
    "   * `sklearn.model_selection.r2_score`\n",
    "5. **deploy** the model\n",
    "\n",
    "Additionally, care needs to be taken to guard against overfillling:\n",
    "* `sklearn.model_selection.train_test_split`: split train & validate\n",
    "* `sklearn.model_selection.KFold`: cross validation\n",
    "* `sklearn.model_selection.GridSearchCV`: put your kfold cv inside a loop that iterates all points span by a grid of hyperparameters \n",
    "\n",
    "For supervised learning you also need to decide on the target variable.<br>\n",
    "The single most important descision you'll make is choosing which target to go after.<br>\n",
    "Think long and hard about what you are going to predict.<br><br>\n",
    "\n",
    "**TAKE YOUR TIME CHOOSING YOUR TARGET!**.<br>\n",
    "Do not be fooled by other people (usually domain experts) telling you what they want predicting,<br>\n",
    "they are almost always not critical enough & and are simply unaware of the importance of getting this right.<br>\n",
    "This is where a good data-scientist will challenge & be a gate-keeper for work doomed to not deliver!<br>\n",
    "\n",
    "Let's start with some simple coding ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "scikit-learn integrates well with numpy & pandas so we can use these tools to load the data.<br>\n",
    "```python\n",
    "import pandas as pd\n",
    "pd.read_csv(...)\n",
    "pd.read_excel(...)\n",
    "pd.read_sas(...)\n",
    "pd.read_sql(...)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titanic.csv')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## let's read in some data, so we can actually do some stuff\n",
    "## side note: piping to filter columns + columns with no missings in Sex or Embarked\n",
    "df = pd.read_csv('data/titanic.csv')\\\n",
    "       .pipe(lambda d: d.loc[~d[['Sex','Embarked']].isna().any(axis=1), \n",
    "                             ['Survived', 'Pclass', 'Sex', 'Embarked', 'Age']\n",
    "                            ]\n",
    "            )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Pclass = df.Pclass.astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## Pre-Processing / Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The columns Sex & Embarked are categorical. Scikit-learn does only works with numerical data.<br>\n",
    "So as a first preprocessing step, these need to be converted into dummy variables ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df.Embarked.value_counts())\n",
    "print(df.Sex.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dummy coding can be achieved by using `sklearn.preprocessing.OneHotEncoder`. Note the steps below are for educational pupose only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## import the encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "## set-up the encoder (sparse=False is almost never used, but convenient here to show the results)\n",
    "ohe = OneHotEncoder(sparse=False, categories=[['S','C','Q'],['male','female']], drop='first')\n",
    "## fit the encoder - note: this is a bit ugly, but before a transformer can be used, it needs to be 'fit'\n",
    "ohe.fit(df[['Embarked','Sex']])\n",
    "## \n",
    "ohe.transform(df[['Embarked','Sex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## creating X & y\n",
    "X = np.hstack((ohe.transform(df[['Embarked','Sex']]), df[['Pclass']]))\n",
    "y = df.Survived\n",
    "## and fit a model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)\n",
    "print('LR model has an accuracy of: ', (lr.predict(X)==y).mean())\n",
    "print('Base Rate / most frequent class as estimate: ', df.Survived.value_counts(normalize=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### A Better Way: Column Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above way to create you data using *np.hstack* is a bit clunky, a better way using *column transformers* ...<br>\n",
    "Below we use **make_column_transformer** to create an object of type ColumnTransformer, that provides us with a `fit`, `transform`, and `fit_transform`.<br>\n",
    "\n",
    "Later in this tutorial, pipelinesare discussed. Pipelines combine multiple processing steps as a list of (Estimator) objects.<br>\n",
    "A pipeline has fit and transform methods. Broadly speaking, it simply calls `fit` and `transform` on the individual objects in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "## define the column_tranformer / \n",
    "col_trans = make_column_transformer(\n",
    "                (OneHotEncoder(drop='first'),['Sex','Embarked']),\n",
    "                remainder='passthrough'\n",
    "            )\n",
    "## apply the column transformer\n",
    "X_transformed = col_trans.fit_transform(df[['Pclass','Sex','Embarked']])\n",
    "## have a look\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## Dealing With Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fitting a model against some data is only half the battle. To have a usefull model it must not only perform well on data thta it was trained on, but also on data that it has not seen. Steted differently, the model must generalize well.<br>\n",
    "\n",
    "The functionality to help us select a model, is provided in `sklearn.model_selection`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "help(sklearn.model_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A simple way to just guard against over-fitting, is done by splitting the data into train, and test.<br>\n",
    "A convenient way is to use the **train_test_split** function sklearn provides.\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, ..., stratify=...)\n",
    "```\n",
    "This needs to be done with care, so we end up with training data that is comparable to the test data.<br>\n",
    "Especially when the target occurs relatively infrequent, pay attention to the **stratify** parameter in the train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## using train & test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.33, stratify=df.Embarked, random_state=42)\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "... and to `fit` the model to the train data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "print('LR model has an accuracy of: ', (lr.predict(X_test)==y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Or, to split the data in 5 & call fit 5 times, each time with one of the groups left out ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## using cross-validation\n",
    "lr = LogisticRegression()\n",
    "cross_val_score(lr, X, y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('LR model has an accuracy of: ', _.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To train a model we need to:\n",
    "* choose/import the mode of choice and configure the model & set some hyper parameters\n",
    "* **fit** the model on the training data\n",
    "* maybe do a grid search over a grid of hyper parameters, or a n-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## use the inspect module to see which classes are defined in sklearn.linear_model\n",
    "import inspect\n",
    "## linear model: OLS + regularized methods like Ridge, Lasso, and Elastic-Net + more advanced Bayesian Ridge regression & ARDRegression +\n",
    "## generalized linear models: logistic + loglinear models + ...\n",
    "import sklearn.linear_model\n",
    "[m[0] for m in inspect.getmembers(sklearn.linear_model, inspect.isclass)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true",
    "heading_collapsed": true
   },
   "source": [
    "## Model Evaluation / Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once the model is fit, the 'quality' of the model needs to be evaluated.<br>\n",
    "sklearn provides a three different APIs for evaluating the quality of a model’s predictions:\n",
    "* score method: estimators have a score method providing a default evaluation criterion for the problem they are designed to solve.\n",
    "* scoring parameter: model-evaluation tools using cross-validation (like: model_selection.cross_val_score and model_selection.GridSearchCV) rely on an internal scoring strategy.\n",
    "* metrics functions: the metrics module implements functions assessing prediction error for specific purposes, see below (also the dos for: classification metrics, multilabel ranking metrics, regression metrics, and clustering metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "[m[0] for m in inspect.getmembers(sklearn.metrics, inspect.isfunction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Key Classes:  Transformers, Estimators, & Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's now time to build a deeper understanding of how the components of sklearn work together.<br>\n",
    "First of all, the base of the object hierarchy is **BaseEstimator**. <br>\n",
    "This class gets combined with so called *mixin* classes to build rich hierarchy of classes ...<br>\n",
    "\n",
    "It helps to think in terms of Transformers and Estimators:\n",
    "* **BaseEstimator**\n",
    "  * **Transformers** (BaseEstimator, TransformerMixin): input data &rarr; output transformed data\n",
    "  * **Estimator** / Model (BaseEstimator, ClassifierMixin / ClusterMixin / RegressorMixin): input data &rarr; output a model\n",
    "* **Pipeline**: stacks a bunch of steps, where the steps are:\n",
    "  * Transformers\n",
    "  * Estimators\n",
    "  * Pipeline: Pipelines can contain Pipelines\n",
    "  * FeatureUnion: joins two Pipelines\n",
    "\n",
    "<br>\n",
    "<font style=\"color:red; font-weight:bold; font-size:150%\">Pipelines form the core of working effectively with scikit-learn.</font><br>\n",
    "<br>\n",
    "Transformers and Estimators form the building blocks, but the way to combine them in pipelines makes scikit-learn powerfull.\n",
    "\n",
    "There is an interesting video with Andreas Mueller, a core developer & release manager of scikit-learn on youtube.<br>\n",
    "He gives a few good tips on how to use the library:\n",
    "* *Everybody should be using pipelines. If you're not using pipelines, you are probably doing it wrong!*\n",
    "* *If you haven't looked at the ColumnTransformer, look at the ColumnTransformer!*\n",
    "* *Pick your metric with care. Accuracy is used as a default, but for unbalanced data, accuracy is a terrible metric.*\n",
    "* *On the importance of pipelines: techniques like FeatureSelection, Imputation, ... should take place inside the pipeline.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers & Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the goal here is build up some intuition, I'm going to simplify things a bit.<br>\n",
    "The distinction between Transformers and Estimators is fuzzy.<br>\n",
    "But, roughly speaking a Transformer transforms the data to go into an Estimator, think model.<br>\n",
    "And, if you strip away the details ...\n",
    "\n",
    "* **Transformers**: classes that process the data (take some input do some processing and produce a transformed versionof the input)<br>\n",
    "  The two important methods that they all have in common:\n",
    "  * `fit(X, [y])`: find params of transformation\n",
    "  * `transform(X, [y])`: appies transformation to X\n",
    "\n",
    "```python\n",
    "class myTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, ...): pass\n",
    "    def fit(self, data): pass\n",
    "    def trasform(self, data): pass\n",
    "```\n",
    "\n",
    "* **Estimator**: take some data, fit/train some model (estimate parameters)<br>\n",
    "  The two important methods that they all have in common:\n",
    "  * `fit(X, y)`: find best fitting params given X and hyper params\n",
    "  * `predict(X, y)`: predict label based on X\n",
    "\n",
    "```python\n",
    "class myEstimator(SomeModelClassMixin, BaseEstimator):\n",
    "    def __init__(self, ...): pass\n",
    "    def fit(self, data): pass\n",
    "    def predict(self, data): pass\n",
    "```\n",
    "\n",
    "The distinction is fuzzy, since most Transformers also need capture parameter values of the transformation.<br>\n",
    "For instance, if we normalize a variable, we need the mean & standard deviation ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pipeline is a sequence of steps, where the step gets executed sequentially.<br>\n",
    "\n",
    "The classic Pipeline is a bunch of Transformers followed by an Estimator.<br>\n",
    "In this case the two most important methods are defined as:\n",
    "* `transform(X, [y])`: call `fit` then `transform` on each step contained inside.\n",
    "* `predict(X, [y])`: call transform on each step then `predict` on the final step \n",
    "\n",
    "A Pipeline is created by passing in a list of tuples of the form: `[(name, transformer), ...]`<br>\n",
    "There is also a convenience function `make_pipeline` that makes this process even easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's create a really simple Transformer class: it simply selects a (set of) column(s)\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class FactorExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, factor): self.factor = factor\n",
    "    def transform(self, data): return data[[self.factor]]\n",
    "    def fit(self, *_): return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='Survived'), df['Survived'], train_size=0.20, stratify=df.Embarked, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pl = make_pipeline(FactorExtractor('Age'), SimpleImputer(strategy='median'), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict_proba(X_test)[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now without Pipelines\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train[['Age']].fillna(X_train.Age.median()), y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test[['Age']].fillna(X_test.Age.median()))[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pl.predict_proba(X_test) == lr.predict_proba(X_test[['Age']].fillna(X_test.Age.median()))).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What went wrong here?<br>\n",
    "Both cases a `LogisticRegression` of Survived on Age & both impute missing values with the mean!\n",
    "\n",
    "The above is a classic mistake: preprocessing on the test data is not the same as preprocessing on the test data!<br>\n",
    "This is easily fixed, but it illustrates the point that Pipelines are a usefull abstraction that can prevent you from making mistakes like this ...<br>\n",
    "\n",
    "The issue is easily fixed here, but immagine when more messy preprocessing is done, and the validation is done by a co-worker, or when cross-validation, or some grid search is used...<br>\n",
    "(where it is important that the preprocessing is part of the pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.Age.median(), X_test.Age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pl.predict_proba(X_test) == lr.predict_proba(X_test[['Age']].fillna(X_train.Age.median()))).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "## HistGradientBoostingClassifier is very much like XGBoost, but still experimental in this version of scikit-learn\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "numerical_features   = ['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([\n",
    "    ('impute',  SimpleImputer(strategy='most_frequent')),\n",
    "    ('dummies', OneHotEncoder(drop='first')) \n",
    "])\n",
    "num_pipe = Pipeline([\n",
    "    ('impute',  SimpleImputer(strategy='median')),\n",
    "    ('scale',   StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = ColumnTransformer([\n",
    "    ('continuous',  num_pipe, numerical_features),\n",
    "    ('categorical', cat_pipe, categorical_features)\n",
    "])\n",
    "## note specify: remainder='passthrough' if you want the remaining columns to get tagged along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline.fit_transform(X_train)[:5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a pipeline where these preprocessing steps are followed by a HistGradientBoostingClassifier\n",
    "hgb_pipeline = make_pipeline(feature_pipeline, HistGradientBoostingClassifier())\n",
    "hgb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost ensemble algorithm and its variants have proved very, very powerfull & have consitently been in the top entries on Kaggle competitions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show off the power of Pipelines, lets do a 5-fold cross validation on the pipeline ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(hgb_pipeline, pd.concat([X_train,X_test]), pd.concat([y_train, y_test]), cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuncionalTransformer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A FunctionTransformer forwards its X (and optionally y) arguments to a user-defined function or function object and returns the result of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Future Topics ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usefull Transformations\n",
    "  * KBinsDiscretizer\n",
    "  * OneHotEncoder\n",
    "  * FunctionTransformer\n",
    "* Feature Selection\n",
    "  * SelektKBest: select features according to the k highest scores\n",
    "  * RFECV: feature ranking with recursive feature elimination and cross-validated selection of the best number of features.\n",
    "* Model Selection and Evaluation\n",
    "  * Metrics: accuracy, AUC, ROC, F1, ...\n",
    "  * Cross Validation: \n",
    "  * GridSearch: find the best hyper parameters\n",
    "* Dealing with unbalanced data\n",
    "  * Downsampling: relatively effective\n",
    "  * SMOTE: has not proved very effective\n",
    "* Model Deep Dive:\n",
    "  * Supervised models:\n",
    "    * Continuous target\n",
    "    * Discrete Target\n",
    "  * Unsupervised models:\n",
    "    * Clustering\n",
    "    * Anomaly Detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
