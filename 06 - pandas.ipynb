{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Like the data.frame in R, the functionality offered by pandas revolves around in-memory data manipulation.<br><br>\n",
    "There are two important classes defined in the pandas library:\n",
    "1. **Series**, a one-dimensional ndarray with *labeled axis* (including time series) & \n",
    "2. **DataFrame**, a two-dimensional size-mutable, potentially heterogeneous tabular data structure with *labeled axes*\n",
    "\n",
    "DataFrames can be thought of as a dict-like container for Series objects. The *labeled axes* a.k.a. indices is what makes pandas fast and powerfull, but also sometimes confusing if you come from you are used to other datasets like R's data.frame. Give yourself time to get used to the concepts, it will  be worth it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A series (think time-series) is a sequence of values where the elements are labelled **with an index**.<br>\n",
    "You can think of a Series a generalized 1D numpy array.<br>\n",
    "When no index is explicitly specified, pandas uses by default the sequence 0 ... n.<br>\n",
    "When working with timeseries the index is usually a timestamp.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## the easiest to create a Series is probably\n",
    "s1 = pd.Series([2,5,3,4], name='My First Series')\n",
    "s1\n",
    "## note the column on the left (0, ..., 3) is the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Main Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## The main pandas objects consist of three major parts\n",
    "print('Name         :', s1.name)\n",
    "print('Values       :', type(s1.values), 'with values', s1.values)\n",
    "print('Index/Labels :', s1.index)\n",
    "print('Data Type    :', s1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A Series can be viewed as a **generalized numpy array**.<br>\n",
    "As shown above the actual data in a series lives in a numpy.ndarray.<br>\n",
    "The difference is that pandas Series (& DataFrames) have row **labels contained as an index**.<br>\n",
    "An index can be seen as an immutable array.<br>\n",
    "Another way of thinking about a Series is as a specialized dictionary, where the index values are the keys mapping to the Series values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before we dive into the ways pandas can be used to manipulate data, I want to touch on the types of data that can live in a pandas Series / DataFrame.\n",
    "<br><br>\n",
    "Pandas is build on top of NumPy. Therefore **pandas offers all the datatypes NumPy offers**.<br>\n",
    "A numpy array consists of a contigeous linear collection of elements. When the elements are integer, or float, or some other type that uses a given number of bits in memory, pandas is fast and efficient. The numpy type system is very rich, see the [documentation](https://numpy.org/devdocs/user/basics.types.html?highlight=data%20types) for much more info. As a rough summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "| Class | Type | Remarks | Character Code |\n",
    "|---|---|---|---|\n",
    "| **Booleans:** | bool_| compatible: Python bool | '?' |\n",
    "| &nbsp; | bool8 | 8 bits | |\n",
    "| **Integers:** | byte | compatible: C char | 'b' |\n",
    "| &nbsp; | short | compatible: C short | 'h' |\n",
    "| &nbsp; | intc | compatible: C int | 'i' |\n",
    "| &nbsp; | int_ | compatible: Python int | 'l' |\n",
    "| &nbsp; | longlong | compatible: C long long | 'q' |\n",
    "| &nbsp; | intp | large enough to fit a pointer | 'p' |\n",
    "| &nbsp; | int8 | 8 bits | 'int8' |\n",
    "| &nbsp; | int16 | 16 bits | 'int16' |\n",
    "| &nbsp; | int32 | 32 bits | 'int32' |\n",
    "| &nbsp; | int64 | 64 bits | 'int64' |\n",
    "| **Unsigned integers:** | ubyte | compatible: C unsigned char | 'B' |\n",
    "| &nbsp; | ushort | compatible: C unsigned short | 'H' |\n",
    "| &nbsp; | uintc | compatible: C unsigned int | 'I' |\n",
    "| &nbsp; | uint | compatible: Python int | 'L' |\n",
    "| &nbsp; | ulonglong | compatible: C long long | 'Q' |\n",
    "| &nbsp; | uintp | large enough to fit a pointer | 'P' |\n",
    "| &nbsp; | uint8 | 8 bits | 'uint8' |\n",
    "| &nbsp; | uint16 | 16 bits | 'uint16' |\n",
    "| &nbsp; | uint32 | 32 bits | 'uint32' |\n",
    "| &nbsp; | uint64 | 64 bits | 'uint64' |\n",
    "| **Floating-point numbers:** | half | &nbsp; | 'e' |\n",
    "| &nbsp; | single | compatible: C float | 'f' |\n",
    "| &nbsp; | double | compatible: C double | |\n",
    "| &nbsp; | float_ | compatible: Python float | 'd'\n",
    "| &nbsp; | longfloat | compatible: C long float | 'g'\n",
    "| &nbsp; | float16 | 16 bits | 'f2' |\n",
    "| &nbsp; | float32 | 32 bits | 'f4' |\n",
    "| &nbsp; | float64 | 64 bits | 'f8' |\n",
    "| &nbsp; | float96 | 96 bits, platform? | |\n",
    "| &nbsp; | float128 | 128 bits, platform? | |\n",
    "| **Complex floating-point numbers:** | csingle | &nbsp; | 'F' |\n",
    "| &nbsp; | complex_ | compatible: Python complex | 'D' |\n",
    "| &nbsp; | clongfloat | &nbsp; | 'G' |\n",
    "| &nbsp; | complex64 | two 32-bit floats | &nbsp; |\n",
    "| &nbsp; | complex128 | two 64-bit floats | &nbsp; |\n",
    "| &nbsp; | complex192 | two 96-bit floats, platform? | &nbsp; |\n",
    "| &nbsp; | complex256 | two 128-bit floats, platform? | &nbsp; |\n",
    "| **Any Python object:** | object_ | any Python object | 'O' |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As in any other language, when the elements are of variable length, what gets captured is the reference. The actual memory used is allocated outside the array.<br>\n",
    "Take strings, strings typically have variable lengths. So when we have a column of strings pandas stores an array of string object references.<br>\n",
    "Each reference points to a structure in memory that holds some properties (like: length) and the phisical location of a buffer where the len characters of the string are stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## don't worry to much if you do not understand all syntax here\n",
    "answcat = ['strongly disagree', 'disagree', 'neutral', 'agree', 'strongly agree']\n",
    "s1 = pd.Series(np.random.choice(answcat,p=[0.2]*5,size=50))\n",
    "s1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type(s1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use the string via the reference just like any other string in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1[0].upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But, note that the dtype = object. This is pandas way of telling you that it is keeping object references.<br>\n",
    "To explain this a bit further, lets look at the memory_uasege():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This memory usage describes what the actual numpy arrays uses, but does not count the actual memory taken by the strings. To get that do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Keep from this, that pandas can store numeric data very efficient using numpy arrays. All other types get stored using an object reference.<br>\n",
    "Working with these object reference is considerably slower, the reference needs to be followed and interpreted each time an object reference is used.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An important way to speed up pandas is to use categorical wherever applicable.<br>\n",
    "A categorical variable is stores a code that serves as a key into a lookup table where the associated strings / labels are kept.<br>\n",
    "Under the hood pandas works with these codes, which is considerable faster than working with object references to strings.<br>\n",
    "As an added benifit, it is much more efficient way to store the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anscat_categorical = {1:'strongly disagree', 2:'disagree', 3:'neutral', 4:'agree', 5:'strongly agree'}\n",
    "example_short = np.random.choice(range(1,6),p=[0.2]*5,size=50)\n",
    "example_long  = np.array([anscat_categorical[e] for e in example_short])\n",
    "df1 = pd.DataFrame({'short':example_short, 'long': example_long})\n",
    "print(df1.memory_usage(deep=True))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A way to make the variable *categorical* in pandas is using the astype('categorical'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "df2.long = df2.long.astype('category')\n",
    "print(df2.memory_usage(deep=True))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'df1 dtype: {df1.long.dtype}\\ndf2 dtype: {df2.long.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As you can see, the dtype is now **category** with possible values listed.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.long.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.long.memory_usage(deep=True) / df1.long.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We are using less than 20% of the memory, in real world examples this will often be much more dramatic (if the number of possible strings is small and the number of rows is large).<br>\n",
    "**Just as important, all sort of other data manipulations become much faster (grouping, aggregations, selections, ...)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## RangeIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pandas automatically creates an index if none is given. The index created will be a RangeIndex, representing a sequence of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([7,5,3], name='My Series')\n",
    "print(s1,'\\n')\n",
    "print(s1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Apart from the default index that gets created if you do not supply one, you can create one explicitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## we also get a RangeIndex when we specify: index=range(...)\n",
    "s1 = pd.Series([7,5,3], name='My Series', index=range(5,8))\n",
    "print(s1,'\\n')\n",
    "print(s1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The index values relates to a specific element, and does not change if an element is removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## drop returns a new Series with the specific index value removed, but leave the original unchanged, unless ...\n",
    "## the argument inplace=True is given.\n",
    "s1.drop(6, inplace=True)\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The remaining elements keep their index value.<br>\n",
    "Also note that RangeIndex(start=5, stop=8, step=1) can no longer be valid.<br>\n",
    "Under the hood, pandas managed this by changing the index type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is a whole hierarchy of Index classes defined in pandas.<br> \n",
    "For daily use, you let pandas take care of the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## for the interested, or when you need it, you can find out much about the hierarchy using the %pserach magic\n",
    "%psearch pd.core.indexes.[a-zA-Z]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Index: Any Hashable Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An index doesn't have to be integer based. It can be, and often is, strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([7,5,3], name='My Series', index=['Jan','Feb','Mar'])\n",
    "print(s1,'\\n')\n",
    "print(type(s1.index), s1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Actually, an **index can be any hashable data type**.<br><br>\n",
    "A hashable data type is a data type that provides the method \\_\\_hash\\_\\_(). Roughly speaking all primitive data types are hashable and the unmutable collections are hashable as well. As examples, lists and dicts are not allowed, but you could use a tuple as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## many types are hashable in Python: like strings\n",
    "'a string'.__hash__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## or, more adventurous, functions\n",
    "def greater_than_two(a): return(a>2)\n",
    "greater_than_two.__hash__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## or tuples\n",
    "(1,2,3).__hash__()\n",
    "## please note that tuples are also used in MultiIndex (discussed below), so the syntax has some gotcha's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## as an example: to create a Series with an index of type tuple \n",
    "s1 = pd.Series([11,22,33], name='s1', index=[(1,1),(2,2),(3,3)])\n",
    "print(s1,'\\n')\n",
    "print(type(s1.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Also, an index does not have to be unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## note: list('aba') --> ['a','b','a']\n",
    "s3 = pd.Series([1,2,3], name='s1', index=list('aba'))\n",
    "s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## DateTimeIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An important type of index used in **time series** is the **DatetimeIndex**.<br>\n",
    "The DatetimeIndex class provides lots of functionality around date time based indices.<br><br>\n",
    "Pandas provides some usefull functions to generate these, like **date_range**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## to create an index of a sequence of consecutive days, use freq='D'\n",
    "pd.date_range(start='2019-03-26', end='2019-04-02', periods=7) ## freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So if we have data containing daily maximum temperatures, a natural way to store this is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = pd.date_range(start='2019-03-26', end='2019-04-02', freq='D')\n",
    "daily_max_temp_degree_c = pd.Series([12,13,14,13,15,14,15,15], name='Daily Max Temp C', index=idx)\n",
    "daily_max_temp_degree_c.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is also possible to specify multiples in the *freq=* notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## so every Monday from 2019-03-25 to 2019-04-05 is - the day_name() method returns the day name ...\n",
    "print('Check: 2019-03-25 is a', pd.to_datetime('2019-03-25').day_name())\n",
    "## to define multiples, put an integer before the period, so: freq='D' is daily and freq='7D' is weekly\n",
    "pd.date_range(start='2019-03-25', end='2019-04-17', freq='7D')\n",
    "## note that '2019-04-15' is included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## or let's say we want two Mondays\n",
    "pd.date_range(start='2019-03-25', periods=2, freq='7D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## or something with working days using freq='C'\n",
    "idx = pd.date_range(start='2019-03-26', end='2019-04-02', freq='C')\n",
    "pd.Series([f\"{dt.day_name()} work {hr}Hr {':-)' if (hr<8) else ':-('}\" for dt,hr in zip(idx, [8,8,8,3,8,8])], \n",
    "          name='Work Pattern', \n",
    "          index=idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Link](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases) to more info on frequency aliases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pandas provides usefull methods to down/upsample timeseries using **resample**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## create a slightly bigger Series, to demonstrate down sampling\n",
    "s4  = pd.Series(np.random.randn(35), index=pd.date_range(start='2019-03-26', periods=35, freq='D'))\n",
    "s4.head(n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## to down sample to one record per week --> taking the last value of the week\n",
    "s4.resample('W', label='right').last()\n",
    "## label='right' means: the interval is labelled using the 'ending Sunday'\n",
    "## .last() means: take the last value in the interval -- other option: first, mean, median, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## check what pandas is doing ... selecting the Sunday's --> see discussion on selection later :-)\n",
    "s4.loc[s4.index.day_name() == 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## more generically, instead of using one of the many predefined methods, like: last, first, mean, std, ...\n",
    "## we could define our own aggregation function, for instance: lag 1 autocorrelation:\n",
    "def my_aggregation_fun(srs): return(np.NaN if (len(srs)<4) else srs.autocorr(lag=1)) ## NaN is len < 4\n",
    "s4.resample('M', label='right').agg(my_aggregation_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*.resample()*:\n",
    "1. *splits* the series into a set of smaller series (as defined by the first argument),\n",
    "2. *apply* the function, here my_aggregation_fun, and \n",
    "3. *combines* the result back into a resulting Series.\n",
    "\n",
    "This **split-apply-combine** pattern is present everywhere in data-science workflows, and pandas has some nice syntax to do this using *groupby()* on which more later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Index Viewed As Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In many ways an index behaves like a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s51 = pd.Series([7,5,3,7,1], index=pd.Index([1,2,3,4,5]))\n",
    "s52 = pd.Series([4,6,3,2,8], index=pd.Index([    3,4,5,6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## when using the in operator, pandas checks if the element in the index\n",
    "print(f'check: 7 in s51 gives: {7 in s51}')\n",
    "print(f'check: 2 in s51 gives: {2 in s51}')\n",
    "## equivalent to: _ in s51.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "More, specifically, the operators: &, |, and ^ behave like set operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## the indices that are in both sets --> logical AND\n",
    "s51.index & s52.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## the indices that are in either sets --> logical OR\n",
    "s51.index | s52.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## the indices that are in only one of the sets --> logical XOR\n",
    "s51.index ^ s52.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**GOTCHA**: an index behaves like an *immutable array* for the math operators: -, +, \\*, and /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(s51.index + s52.index)\n",
    "print(s51.index - s52.index)\n",
    "print(s51.index * s52.index)\n",
    "print(s51.index / s52.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## MultiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, an index can have multiple levels.<br>\n",
    "As an example assume we have end of month data on accounts.<br>\n",
    "Using the from_arrays() method on the MultiIndex class:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s6  = pd.Series(np.random.randn(9), \n",
    "                name    = 'Fictitious Balance', \n",
    "                index   = pd.MultiIndex.from_arrays([  [1,1,1,2,2,2,3,3,3], \n",
    "                                                       ['201801','201802','201803']*3\n",
    "                                                    ], \n",
    "                                                    names=['account','yyyymm']\n",
    "                                                   )\n",
    "              )\n",
    "s6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s6.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This becomes rather usefull when selecting or aggregating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s6.loc[:,'201803']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Many aggregation methods defined on the Series (and DataFrames) take *level=* as argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## aggregate by account\n",
    "s6.sum(level='account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## aggregate by year/month\n",
    "s6.sum(level='yyyymm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There will be more on aggregating, slicing, & dicing data later on. For now, observe that MultiIndex (or hierarchical indexing) can lead to natural / readable syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The **DataFrame** lies at the hart of many Data Science workflows. It holds a two-dimensional table of data where each column can be be of a different data type. A DataFrame is build from a set of Series, all sharing the same index.<br><br>\n",
    "Let's start by creating a DataFrame from two Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## lets create some random data\n",
    "s1 = pd.Series(np.random.randn(4), name='series1', index=[1,2,3,4])\n",
    "s2 = pd.Series(np.random.randn(4), name='series2', index=[3,4,5,6])\n",
    "s3 = pd.Series(np.random.randn(4), name='series3', index=[5,6,7,8])\n",
    "## the __init__() method of DataFrame accepts a dict of Series\n",
    "df = pd.DataFrame({'s1': s1, 's2': s2, 's3': s3})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that pandas automatically lines up the indices and fills with NaN where the values are missing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Main Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Just like with Series, the three important part of a DataFrame are:\n",
    "* columns ==> column index\n",
    "* index   ==> row index\n",
    "* values  ==> the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To get some summary information regarding the DataFrame, use *.info()*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Selecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We already used indexing / slicing / selecting data from a Series.<br>\n",
    "In the following we will take a deep-dive into selecting data from a DataFrame.<br><br>\n",
    "\n",
    "There are two ways to reference elements of the series:\n",
    "1. **.loc[]** & **.at[]**: using **index values** & \n",
    "2. **.iloc[]** & **.iat[]**: **location based** (n-th element & not element with index n)\n",
    "\n",
    "Note: it is also possible to use the **[]** operator directly.<br>\n",
    "But, it can be confusing. To be discussed last, once the basics are nailed down\n",
    "<br><br>\n",
    "Direct use of operator[] is usefull in the Notebook, but discouraged in production code.<br>\n",
    "(from the docs) ... *since the type of the data to be accessed isn’t known in advance, directly using standard operators has some optimization limits. For production code, we recommended that you take advantage of the optimized pandas data access methods exposed in this chapter*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Single Element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's look at some simple examples: *.at[]* & *.iat[]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## element with row index = 1 and column (index) = s1 (position 0, 0)\n",
    "df.at[1,'s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## the same element now using it's position 0, 0\n",
    "df.iat[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is basically all you can do with *.at[]* and *.iat[]*.<br>\n",
    "They are simple and fast, but less flexible as *.loc[]* and *.iloc[]*.<br>\n",
    "You could do the same thing using *.loc[]* and *.iloc[]*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[1,'s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But *.loc[]* and *.iloc[]* can also deal with more complicated selections.\n",
    "<br><br>\n",
    "The use case for *.at[]* & *.iat[]* is simply speed ...\n",
    "<br><br>\n",
    "*From the documentation*: Since indexing with **.loc[]** & **.iloc[]** must handle a lot of cases (single-label access, slicing, boolean indexing, etc.), it has a bit of overhead in order to figure out what you’re asking for. If you only want to access a scalar value, the fastest way is to use the **at[]** and **iat[]** methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rs = pd.Series(0,range(10000))\n",
    "df = pd.DataFrame(np.random.randn(10000,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in rs.index: rs.loc[i] = df.loc[i,0] + df.loc[i,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in range(10000): rs.iloc[i] = df.iloc[i,0] + df.iloc[i,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in rs.index: rs.at[i] = df.at[i,0] + df.at[i,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in range(10000): rs.iat[i] = df.iat[i,0] + df.iat[i,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The *.at[]* and *.iat[]* show some pretty good speedups here ...\n",
    "<br><br>\n",
    "But ... you should **always use 'vectorized computation'** in pandas and numpy (and R and probably any intepreted language that does not have compiler optimizations to make it fast), as show below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "rs = df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Below we delve into more complex selection mechanisms that allow for vecorized computations on mor complex sub-selections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Boolean Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A pattern often used is boolean indexing. To quickly select a subset where some condition holds, we pass in a Series (or array or list) of boolean values.<br>\n",
    "In pandas boolean indexing is supported using *.loc[]*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10,3), columns=['c1','c2','c3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## define a simple expression that returns a Series of booleans where column c1 > 0\n",
    "df.c1 > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## to select all the rows where this condition is True\n",
    "df.loc[df.c1 > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you want to use multiple conditions, you **must wrap each condition in ()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[(df.c1 > 0) & (df.c3 < 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another way of doing the same is using the query method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.query('c1 > 0 & c3 < 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This way of working with your data is what makes pandas work. If you work with poandas (or numpy, R data frames, or ...) you need to become familiar at this way of working. Working with loops will slow your code down and make it much less readable and maintainable.\n",
    "<br><br>\n",
    "Let's replace all the negative elements with 0, the bad way and the good way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10000,2), columns=['c1','c2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "## The BAD way. Don't do this!!!!\n",
    "res = df.copy()\n",
    "for row_index in range(res.shape[0]):\n",
    "    for col_index in range(res.shape[1]):\n",
    "        if res.iat[row_index,col_index] < 0:\n",
    "            res.iat[row_index,col_index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "## A better way ...\n",
    "res = df.copy()\n",
    "## loop over columns (more on iterating over Series and DataFrames later)\n",
    "for _, col in res.items():\n",
    "    ## select elements where col < 0 is True and replace with 0\n",
    "    col.loc[ col < 0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "## The Good way. Instead do this!!!!\n",
    "res = df.copy()\n",
    "## shorter, prettier, and arguably more readable ...\n",
    "res.where( res < 0, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Using List or Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10,3), columns=['c1','c2','c3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[[1,6,9,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[[1,6,7,9],['c3','c1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## note that negative index values are allowed\n",
    "df.iloc[[3,2,1], ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pandas can select data using the slice notation *lower*:*upper*:*step*<br><br>\n",
    "**GOTCHA**: index-based slicing using .loc[] **includes** the upper bound!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(low=1, high=9, size=(5,5)), columns=['c1','c2','c3','c4','c5'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## rows with index values 1,2, & 3 (upper bound included in index slicing)\n",
    "df.loc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## rows at position 1 & 2 (upper bound not included in position slicing)\n",
    "df.iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[1:3,'c1':'c4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## first two rows by first two columns\n",
    "df.iloc[:2,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since the index does not have to consist of unique values and the index does not have to be increasing or decreasing, slicing with **index** can fail or give unexpected results.<br>\n",
    "The process is to obtain a index slice is:\n",
    "1. get unique position of left value (throws KeyError if not unique)\n",
    "2. get unique position of right value (throws KeyError if not unique)\n",
    "3. return the sequence between these positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## lets create a series with an index that is not strictly increasing or decreasing and contains duplicate values \n",
    "df = pd.Series([1,2,3,4,5,6,7,8],index=list('acdfebae'))\n",
    "## index value 'a' not unique\n",
    "try:\n",
    "    print(df.loc['a':'d'])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "## index value 'e' not unique\n",
    "try:\n",
    "    print(df.loc['b':'e'])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "## index values 'f' & 'b' unique, but ... does this make sense?\n",
    "try:\n",
    "    print(df.loc['f':'b'])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.index.is_monotonic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Slicing using the **position** based syntax is always unambiguous!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Callable Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, you can pass in a function (or callable) that takes one argument (the calling Series or DataFrame) and returns valid output for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "df = pd.DataFrame(np.random.randint(low=1, high=9, size=(5,5)), columns=['c1','c2','c3','c4','c5'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## all rows that have a column max\n",
    "def select_rows_with_1s(df): \n",
    "    return((df==1).sum(axis=1) > 0)\n",
    "\n",
    "## all rows that have a column containing a column max\n",
    "def select_rows_with_column_max(df):\n",
    "    return(set(df.idxmax(axis=0)))\n",
    "\n",
    "## put the functions in a dict\n",
    "funs = {'1': select_rows_with_1s, '2': select_rows_with_column_max}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ixfun = input('''\n",
    "1: to select all rows that have at least one 1\n",
    "2: to select all rows that contain a column max\n",
    "Choose your function: ''')\n",
    "\n",
    "df.loc[ funs[ixfun] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Shortcut: [] directly on DataFrame[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, you can use the syntax *DataFrame[]*. This syntax is **very** confusing if you do not understand the basics. The behaviour of *DataFrame[]* depends on the arguments given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## lets create a dataframe that shows of the behaviour.\n",
    "## spend some time in understanding this, it will pay off!!\n",
    "df = pd.DataFrame(np.random.randn(5,3), index=[1,2,3,4,5], columns=[1,2,3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Single value --> argument interpreted as column index value / name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "List of values --> argument interpreted as list of column index values / column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[[3,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "List of booleans --> argument interpreted as list of booleans for the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[[True,False,False,True,False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Slice --> argument interpreted as a row slice using position (0-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## position 1 is the second row & since we are doing positional slicing the upper bound 4 is excluded\n",
    "df[1:4]\n",
    "## note: 1,2,3 (excluding 4) in position have index values: 2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You often see these selections chained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[[True,False,False,True,False]][[3,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In summary:\n",
    "\n",
    "| DataFrame[] | DataFrame.loc[] / DataFrame.iloc[] | position / index |\n",
    "| --- | --- | --- |\n",
    "| df[1] | df.loc[:,1] | index based |\n",
    "| df[[1,2]] | df.loc[:,[1,2]] | index based |\n",
    "| df[[True, False, ...]] | df.loc[[True, False, ...],:] | n/a |\n",
    "| df[1:4] | df.iloc[1:4,:] | position based |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Two final remarks:\n",
    "1. when column names do not clash with the Python reserved words / special characters then<br>\n",
    "```df['col1']``` is equivalent to ```df.col1``` (**this get used all the time!**)\n",
    "2. use: ```df[condition] = replacement``` to replace all values in a DataFrame base on a matrix of booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns={1:'col1',2:'col2',3:'col3'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[df<0] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Non-Existing Row/Column Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Referencing a key that does not exist, will throw a KeyError exception.<br>\n",
    "Assigning to a key that does not exist, will add the index and assign the value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(42,index=['a','b'],columns=['c1','c2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Reference a non-existing row/column --> trows a KeyError or IndexError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## this will throw a KeyError\n",
    "try:\n",
    "    df.loc['c']\n",
    "except KeyError as e:\n",
    "    print(repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df.loc[:,'c3']\n",
    "except KeyError as e:\n",
    "    print(repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df.iloc[:,2]\n",
    "except IndexError as e:\n",
    "    print(repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df.iloc[2,:]\n",
    "except IndexError as e:\n",
    "    print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Assigning to a non-existing row/column --> add row/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc['c'] = [84,168]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'c3'] = 99\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc['c','c3'] = 42\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'c4'] = [1,22,333]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## so to add a column with row-sums\n",
    "df['total'] = df.sum(axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that since a DataFrame is a collection of Series, indexed by their name (aka column name):\n",
    "* adding a column using the above syntax is efficient\n",
    "* adding a row by using the above syntax is very inefficient. Worse case:\n",
    "  * a new numpy.array for each column needs to be made\n",
    "  * all the data needs to be copied over\n",
    "  * the original deleted (by the garbage collector at some later point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## you can also insert a column in a specific location\n",
    "df.insert(4,'avg',df.iloc[:,:3].sum(axis=1))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## IndexSlice For Complex MultiIndex Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In certain complex multi-index cases slicing is not possible using tuple notation.<br>\n",
    "More specifically when you want to keep one level of a multi index fixed and slice other levels.<br>\n",
    "This sound complicated, so lets generate an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame( np.random.randn(15,9), \n",
    "                   index   = pd.MultiIndex.from_arrays([  [1]*5 + [2]*5 + [3]*5, \n",
    "                                                          ['201801','201802','201803','201804','201805']*3\n",
    "                                                       ], \n",
    "                                                       names=['account','yyyymm']\n",
    "                                                      ),\n",
    "                   columns = pd.MultiIndex.from_arrays([  ['atm']*3 + ['contactless']*3 + ['mobile']*3,\n",
    "                                                          ['nr','vol','avg']*3\n",
    "                                                       ], \n",
    "                                                       names=['account','yyyymm']\n",
    "                                                      )\n",
    "                 )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.index.levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns.levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The way to access the elements is by using tuples for each axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[(2,'201803'),('contactless','avg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It you do not use tuples, pandas will assume the first level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[1,'mobile']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Also slicing works as expected on this level.<br>\n",
    "Lets assume we want the atm data for accounts 1 & 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[1,'atm':'contactless']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But, slicing on deeper levels is not possible, without using the IndexSlice object. The following way to select the 2018 data will raise an exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[(:,'201803'),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To slice generically over any level of a MultiIndex, use IndexSlice ...<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[ pd.IndexSlice[1, '201801':'201803'], pd.IndexSlice['atm':'contactless', 'avg'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Copy Or View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Most methods in pandas will return a copy of the data, but not always!<br>\n",
    "This is a potential minefield in pandas<br><br>\n",
    "\n",
    "Here's the rules:\n",
    "1. If **inplace=True** is provided, it will **modify in-place** (only some operations)\n",
    "2. An indexer that **sets** using (.loc[]/.iloc[]/.at[]/.iat[] = ) will **set inplace**.\n",
    "3. An indexer that gets **(part of a) Series** / **complete DataFrame** is **almost always a view**.\n",
    "4. An indexer that gets a **more complicated subset** DataFrame from the original DataFrame is always a **copy**.\n",
    "5. All **operations** / **methods** generate a **copy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## generate some toy data\n",
    "s1 = pd.Series(np.random.randn(3), name='s1', index=[0,1,2])\n",
    "s2 = pd.Series(['a','b','c'],      name='s2', index=[1,2,3])\n",
    "df = pd.DataFrame({'s1': s1, 's2': s2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[:2,'s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## rule 3: get part of single Series --> view\n",
    "## change the original & the change is reflected in the view\n",
    "tmp = df.loc[:2,'s1']\n",
    "df.loc[1,'s1'] = 99\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## rule 3: get part of single Series --> view\n",
    "## change the original & the change is reflected in the view\n",
    "tmp = df.loc[:1,'s2'].copy()\n",
    "tmp[0] = 'A'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## rule 3: complete DataFrame --> view\n",
    "## change the original & the change is reflected in the view\n",
    "tmp = df\n",
    "df.loc[2,'s2'] = 'X'\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## rule 4: subset of rows and columns --> copy\n",
    "## change to the copy do not propegate back to the original ...\n",
    "tmp = df.loc[:,['s1','s2']]\n",
    "tmp.loc[3,'s1'] = 66\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One question that pops up often on StackOverFlow is about SettingWithCopyWarning. You will get this warning when working with pandas. This warning is issued when in a single line of code you try to set a value immediately after a get operation that might return a copy. The best way around this warning is to use make sure the update is achieved in a single operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[3:4]\n",
    "## ... df[3:4] will be executed and will return a DataFrame containing a subset of the original --> a copy (rule 4)\n",
    "## the subsequent set command copy.['s1'] = value  will issue a SettingWithCopyWarning waring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## assigning to a view on a copy does not achieve the desired result ... pandas warns you\n",
    "df[3:4]['s1'] = 33\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## solution is to make sure it is a single operation:\n",
    "df.loc[2:4,'s1'] = 33\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In object oriented programming languages the behaviour of operators like: +, -, /, \\*, are often implemented to give them intuitive usage.<br>\n",
    "It's what makes NumPy and SciPy (or Matlab, or ...) so elegant for computation.<br><br>\n",
    "Just like in NumPy, where a calling an operation on an array returns an array, in pandas many operations are defined for Series and DataFrames and return Series or DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Logical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have allready used these throughout ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([-1,3,-2,5,8])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1 < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1[s1<0] = 0\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[-1,3],[-2,5],[8,-2]], columns=['c1','c2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## you can do things like\n",
    "df[df<0] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Mathematical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(s1 + 5) // 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since Series and DataFrames consist of NumPy arrays, we can do things like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(s1 - np.mean(s1)) / np.std(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type((s1 - np.mean(s1)) / np.std(s1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Or lets say we want to normalize a column in a DataFrame to [0,1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,51,size=(5,2)), columns=['r1','r2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## note that we can add a column by assignment, see section 5.7\n",
    "df['r1_norm'] = (df.r1 - np.min(df.r1)) / (np.max(df.r1) - np.min(df.r1))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Many methods defined for numpy arrays are also implemented for Series.<br>\n",
    "For instance, instead of using the Numpy min & max we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'r1'].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(df.loc[:,'r1']).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[:,'r1'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These are also defined for DataFrames. By default the method is applied to each column, returning a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The DataFrame methods have an **axis=** argument. This is used to indicate if the method is applied column-wise, over axis=0 (collapse over 'rows'), or axis=1 (collapse over 'columns').<br>\n",
    "Note if you do not supply the argument, pandas will use the default axis=0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[['r1','r2']].sum(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So to compute the Z-score for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## compare to:  (df - np.mean(df)) / np.std(df)\n",
    "dr12 = df[['r1','r2']]\n",
    "res = ((dr12 - dr12.mean()) / dr12.std()).rename(columns={'r1':'z_r1', 'r2':'z_r2'})\n",
    "pd.concat([df,res],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Or, for the row-wise Z-score for the first two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[f'C{ix:>02}' for ix in range(1,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(5,10), columns=[f'C{ix:>02}' for ix in range(1,11)])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that the '-' operator does not play well with the result obtained using axis=1  (when we use: dataframe - series).<br>\n",
    "Basically, the operators will want to operate row wise: here, for each row subtract row mean from row ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    " df.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(df - df.mean()) / df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To make it work:\n",
    "* use transpose\n",
    "* use the numpy np.newaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "((df.T - df.T.mean()) / df.T.std()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(df - df.mean(axis=1)[:,np.newaxis]) / df.std(axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Below we give a few more examples of methods that pandas has to offer. We can only touch on a small subset of capabilities.<br>\n",
    "But, as before, once you understand the basics, you can figure out how to solve specific problems as and when they appear (with the help of google, stackoverflow, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Predefined Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,4,size=(10,8)), columns=['c1','c2','c3','c4','c5','c6','c7','c8'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## row median\n",
    "df.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## quantiles for each column\n",
    "df.quantile(q=[0.25], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.quantile(q=[0.25,0.50,0.75], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## with some fancy lambda stuff to generate a new index\n",
    "df.quantile(q=[0.25,0.50,0.75], axis=0)\\\n",
    "  .rename(index = lambda v: f'Q{int(100*v)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.Series([1,2,3,2,4,2,3,1,np.NaN], dtype=pd.Int16Dtype)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Series methos: the frequency of unique values\n",
    "df.c1.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Series method: timeseries specific stats\n",
    "df.c1.autocorr(lag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## auto-correlation is the correlation between a series and itself shifted by lag\n",
    "## as in:\n",
    "df.c1.corr(df.c1.shift(periods=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## use map to recode from one set of values to another\n",
    "mf = pd.Series(['Male','Female','Female','Male','Female'])\n",
    "pd.concat([mf,\n",
    "           mf.map({'Female':1, 'Male':2})\n",
    "          ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instead of a dict containing the mappings, the *map()* method can also be called with a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mf.map(lambda x: 1 if (x=='Female') else 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This makes *map()* rather powerfull and a good bridge to the next section. In case a pre-canned method does not exist, it is straightforward to implement the functionality yourself using *apply* & *agg*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## DIY: applymap, apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When a computation is not supplied out of the box, you can implement it using: applymap, apply, & agg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To apply an arbitrary function to each element in a DataFrame use applymap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3],[4,2,6],[2,2,1]], columns=('c1','c2','c3'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.applymap(lambda x: 2*x if ((x%2)==0) else 3*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## apply with axis=0 --> calls the function once for each column \n",
    "df.apply(lambda x: x.name)\n",
    "## same as: df.apply(lambda x: x.name, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## apply with axis=1 --> calls the function once for each row\n",
    "df.apply(lambda x: x.name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## calls the function once for each row --> for each row randomly take three elements\n",
    "df.apply(lambda x: x.mean(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that when the function returns a Series, and the Series get concatenated into a DataFrame, the result will line up the rows based on the column index. You could add a **.reset_index(drop=True)** to make sure all the row sample Series have index=[0,1,2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.apply( lambda x: x.sample(n=3).reset_index(drop=True), axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, there is also the **agg** method, that enables the definition of multiple functions (possibly for each column individually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.agg({\n",
    "    'c1': ['sum'],\n",
    "    'c2': ['sum', 'mean'],\n",
    "    'c3': ['mean']\n",
    "}).unstack().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Windowing: rolling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instead of applying a function to each element or each column or each row, you can apply a function to a rolling window of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(5,2),columns=('c1','c2'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## if you want to apply the sum over a window of three elements where two elements exist\n",
    "df.rolling(3,min_periods=1).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## generate some timeseries data\n",
    "dti = pd.date_range(start='2019-01-01 12:00:00', periods=50, freq='4H')\n",
    "srs = pd.Series(20*(np.random.rand(50)-0.5).cumsum(), index=dti)\n",
    "## smooth by taking a rolling mean over 12 hr\n",
    "df = pd.DataFrame({ 'raw':srs,\n",
    "                    'smoothed':srs.rolling('12H').mean()\n",
    "                  })\n",
    "## and plot\n",
    "df.plot(figsize=(16,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Windowing using an arbitrary function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Just like **apply()** on the whole Series / DataFrame, you can use apply() on the rolling window.<br>\n",
    "Lets say you are not happy with taking the mean, but you want to weigh based on time delta ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['smooth2'] = srs.rolling(5).apply( lambda vec: np.dot(vec,np.array([1,2,3,4,5])/15), raw=True  ) ## raw = True means the function will receive an ndarray\n",
    "df.plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And as before, you can also use **agg()**. When calling agg() on a Series, you can pass in a dict with multiple functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## same thing, but now using the more generic agg() method (which will work on any function)\n",
    "df.raw\\\n",
    "  .rolling(3, min_periods=1)\\\n",
    "  .agg({ 'median': lambda vec: np.median(vec), \n",
    "         'range':  lambda vec: max(vec)-min(vec)\n",
    "       })\\\n",
    "  .plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It might not be suited as a big-data tool out of the box, and it does have its downside. But, once you get fluent in manipulating your data with pandas, there's nothing really like it :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Accessors\n",
    "The last section in this part is about accessors. Accessors are used to fascilitate working with strings, dates, and datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([ ('Florence Nightingale', 1820, 1910),\n",
    "                    ('Karl Pearson', 1857, 1936),\n",
    "                    ('Ronald Fisher', 1890, 1962),\n",
    "                    ('Gertrude Cox', 1900, 1978),\n",
    "                    ('John Tukey', 1915, 2000),\n",
    "                    ('Carl Gauss', 1777, 1855)\n",
    "                  ], columns=('name', 'born', 'deceased'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.name.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type(df.name.str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So we can just string these together ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.name.apply(lambda s: s.split()[-1].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['surname'] = df.name.str.split().str[-1].str.upper()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NP  = 10\n",
    "dti = pd.date_range(start='2019-01-01 12:00:00', periods=NP, freq='7D')\n",
    "df  = pd.DataFrame({'dti':dti, 'val':np.random.randn(NP)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.insert(1,'yyyymm', df.dti.dt.strftime('%Y%m'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Changeing Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is a good paper by [Hadley Wickham](https://vita.had.co.nz/papers/tidy-data.pdf) on so called 'tidy' data. In practice, data comes in all shapes and sizes, and cleaning, massaging and prepping data into a shape that is usefull for analysis and visualization often takes up most of the time in Data Science workflows.\n",
    "<br><br>\n",
    "In tidy data:\n",
    "1. Each variable forms a column.\n",
    "2. Each observation forms a row.\n",
    "3. Each type of observational unit forms a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/countrystats.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the countrystats data it looks like the  'Indicator Name' column contains many variables. From a 'tidy'\n",
    "data point of view the different indicators should all have their own column ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['Indicator Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Let's Do Some Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Clean up the names, so they can be used as column names.<br><br>\n",
    "To do string manipulation in pandas, we use the string accessor **.str**.<br>\n",
    "Here it is slightly more involved, looks like we want to define a seperate function to do the string manipulation and then call **apply()**.<br><br>\n",
    "The function needs to:\n",
    "1. convert to lower case\n",
    "2. split the string on a character other than space or [a-z] and take the first\n",
    "3. strip the whitespace\n",
    "4. replace remaining spaces for underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## define the function to be applied to all the strings\n",
    "## basically: use a regular expression to:\n",
    "## 1. split the substrings made up of charecters not in a-z, A-Z, 0-9 --> re.split('[^a-z0-9]+', s.lower())\n",
    "## 2. and join the bits with '_' --> '_'.join([...])\n",
    "def clean_indicator_name(name): return '_'.join([e for e in re.split('[^a-z0-9]+', name.lower()) if e != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['Indicator Name'] = df['Indicator Name'].apply(clean_indicator_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['Indicator Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## rename the columns\n",
    "df.rename(columns={'Country Name':   'location',\n",
    "                   'Indicator Name': 'indicator',\n",
    "                   'Year':           'year',\n",
    "                   'Value':          'value'\n",
    "                  },\n",
    "          inplace=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the purpose of showing the functionality, lets filter the data & only keep records where:\n",
    "* location in ['Argentina','Sweden','United Kingdom'] &\n",
    "* year > 1990 and indicator is tax or gdp related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df[  (df.location.isin(['Argentina','Sweden','United Kingdom'])) & \n",
    "          (df.year > 1990) &\n",
    "          [('tax' in idx) | ('inflation' in idx) for idx in df.indicator]\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(['indicator','year','location']) \\\n",
    "       .reset_index(drop=True)[['indicator','year','location','value']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## unstack(): from row index to column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.set_index(['year','location','indicator'], drop=True).unstack().unstack(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use unstack to 'unstack' a level of the row index by moving it to the column index.<br>\n",
    "Sound complicated, it is not:\n",
    "1. create a more meaningfull index for the DataFrame: location, indicator, year\n",
    "2. unstack the indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## unstack: by default moves the inner-most row index (level=-1) into the column index (inner-most level of the resulting column multi-index)\n",
    "df_unstack = df.set_index(['year','location','indicator'], drop=True).unstack()\n",
    "df_unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_unstack.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_avg_std = df.set_index(['year','location','indicator'], drop=True).rename(columns={'value':'mean'})\n",
    "df_avg_std['std'] = np.abs(np.random.rand(df_avg_std.shape[0]))\n",
    "df_avg_std\n",
    "## df_avg_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_avg_std_unstack = df_avg_std.unstack()\n",
    "df_avg_std_unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_avg_std_unstack.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[f'{l0}_{l1}' for l0,l1 in df_avg_std_unstack.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_avg_std_unstack.columns = [f'{l0}_{l1}' for l0,l1 in df_avg_std_unstack.columns]\n",
    "df_avg_std_unstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A usefull method on pandas DataFames is **pipe**. Tipe takes a function that takes a DataFrame and returns a DataFrame.<br>\n",
    "Hence pipe() can be used to stitch operation together, where each step takes in input of the previous step and produces the output for the next step.<br><br>\n",
    "```python\n",
    "df.pipe(operation1).pipe(operation2).pipe(operation3).pipe(operation4)\n",
    "```\n",
    "Below pipe() is used to 'fix' the column multi-index without the need to break the pipeline ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## using pipe because the need to reference the result of the previous step explicitly: result_previous.columns = ...\n",
    "def flatten_columns(df):\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "    df.columns.name = None\n",
    "    return df\n",
    "\n",
    "df.set_index(['year','location','indicator'], drop=True)\\\n",
    "  .unstack() \\\n",
    "  .pipe(flatten_columns) \\\n",
    "  .inflation_gdp_deflator_annual \\\n",
    "  .unstack() \\\n",
    "  .plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.set_index(['year','location','indicator'], drop=True) \\\n",
    "  .unstack() \\\n",
    "  .pipe(flatten_columns) \\\n",
    "  .inflation_gdp_deflator_annual \\\n",
    "  .unstack() \\\n",
    "  .plot(kind='barh', figsize=(20,5), width=0.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## stack(): from column index to row index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As expected, stack does the exact oposite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_unstack = df.set_index(['year','location','indicator'], drop=True).unstack().pipe(flatten_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_unstack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_unstack.stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_unstack.stack().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_df = df.set_index(['location','indicator','year']).unstack(['indicator','year'])\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**melt** pivots all columns into variables & only keeps columns you specify in id_vars=...<br>\n",
    "So, if you don't specify anything, you loose *location* here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_df.melt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is basically the same as explicitly listing all the tuples of the multi-index columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_df.melt(value_vars=[(l0,l1,l2) for l0,l1,l2 in my_df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To keep the location, we need to first pull it out of the index, and then tell melt to keep that column as an id_var ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we are still left with this annoying column that corresponds to the 0-th level of the column multi-index. To get rid of this you could first droplevel(0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_df.columns = my_df.columns.droplevel(0)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_df.reset_index().melt(id_vars='location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## pivot_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.pivot_table(index=['location','indicator'], columns='year', values='value').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.pivot_table(index=['location','indicator'], values='value', aggfunc=['median','mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Merging and Joining DataFrames can be done by: \n",
    "* concat: concatenate row's or column's depending on axis= --> only support 'inner' joins and 'outer' joins (default)\n",
    "* join & merge: like the sql join, both can be used to do all of the joins you'd want do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## lets create some data\n",
    "lft = pd.DataFrame({'lgrp':[1,1,1,2,2], 'lval': np.random.randint(1,11,size=5)}, index=[2,3,4,5,6])\n",
    "rgt = pd.DataFrame({'rval': np.random.randint(1,11,size=5)},                     index=  [3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## concat: row-wise or column-wise concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "concat can only do 'inner' and 'outer' joins (the default is outer) ...<br>\n",
    "axis=0: concat rows<br>\n",
    "axis=1: concat columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([lft,rgt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([lft,rgt], join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that the index in not changed, which for column-wise concatenation is natural, but for row-wise concatenation you might want to use *.reset_index()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([lft,rgt],axis=0,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## merge: to handle all your joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Merge is a more generic method to join DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## lest create some data\n",
    "lft = pd.DataFrame({'key':[2,3,4,5], 'val': np.random.randint(1,11,size=4)})\n",
    "rgt = pd.DataFrame({'key':[3,4,5,6], 'val': np.random.randint(1,11,size=4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## to do an inner join --> equivalent to how='inner'\n",
    "pd.merge(left=lft, right=rgt, on='key', suffixes=('_left','_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=lft, right=rgt, on='key', how='outer', suffixes=('_left','_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=lft, right=rgt, on='key', how='left', suffixes=('_left','_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=lft, right=rgt, on='key', how='right', suffixes=('_left','_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Split-Apply-Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One workflow that pops up everywhere, is split-apply-combine: split the dataset row-wise into groups, do some processing on each group individually and then combine the results.<br>\n",
    "Pandas supports this through **groupby()** which returns a DataFrameGroupBy. Further processing on this DataFrameGroupBy object will apply on each group and combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/drinksbycountry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Also the DataFrameGroupBy is iterable, so:\n",
    "```python\n",
    "for grp, df_grp in df.groupby('some_grouping_var'):\n",
    "    ## do some stuff\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type(dfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfg = df.groupby('continent')\n",
    "print(type(dfg))\n",
    "for grp, df_grp in dfg:\n",
    "    print(grp, df_grp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('continent').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('continent')[['beer_servings','spirit_servings']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### DataFrameGroupBy.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_group_df(df):\n",
    "    df_pct = df.sum() / df.sum().sum()\n",
    "    return(df_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('continent')[['beer_servings','spirit_servings','wine_servings']].apply(process_group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('continent')[['beer_servings','spirit_servings','wine_servings']].apply(lambda df: df.sum() / df.sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### DataFrameGroupBy.agg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With the **agg()** you can apply processing on individual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_col(srs):\n",
    "    return srs.median()\n",
    "## \n",
    "df.groupby('continent')\\\n",
    "  .agg({ 'beer_servings': ['mean', 'sum'],\n",
    "         'spirit_servings': ['std', 'count'],\n",
    "         'wine_servings': [process_col]\n",
    "       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### DataFrameGroupBy.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With the **transform()** you can apply processing but the DataFrame/Series will have same axis length.<br>\n",
    "Probably easiest to compare with SQL windowed function with a partition by in the *groupby()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df['continent'], df.groupby('continent')[['beer_servings','spirit_servings']].transform('mean')], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This returns a Series / DataFrame with the same index as the original, so we can concat, merge, join, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[['beer_servings','spirit_servings']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So, to create a DateFrame with the continent mean subtracted for beer_servings & spirit_servings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(df[['beer_servings','spirit_servings']] - df.groupby('continent')[['beer_servings','spirit_servings']].transform('mean')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, instead of splitting the dataset into distinct groups and process the groups individually, pandas also makes it easy to do processing on a sliding window using **window()**.<br>\n",
    "This works similar to groupby(), but instead of a DataFrameGroupBy it returns a object of type window.Rolling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "srs = pd.Series(np.random.randn(100).cumsum(), index=pd.date_range(start='31-01-2019', freq='D', periods=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "srs[:12].rolling(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To operate on the pandas.core.window.Rolling, you can call methods directly, of operate use apply and operate on the numpy array that is passed in each time ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "srs[:12].rolling(3, min_periods=1).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note: currently a numpy array is passed in. In future (probably from 1.0 onward) a Series will be passed in.<br>\n",
    "(The raw=True is used to silence the warning message regarding this changing behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "srs.rolling(3).apply(lambda win: np.median(win), raw=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Basic Visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Jupyter / pandas has some usefull facitilies to highlight elements in the output.<br>\n",
    "It also has some plot methods directly defined on the Series / DataFrame.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## lets create a DataFrame with the same row & column index\n",
    "df = pd.DataFrame(np.random.randn(4,3), index=[1,2,3,4], columns=[1,2,3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## return some css styling based on the value\n",
    "def vis_highlight_negative(cell):\n",
    "    return(f\"{'color: blue' if (cell < -1) else 'color: black'}; \" +\n",
    "           f\"{'background: yellow' if (cell < -1) else ''}\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## applymap: function gets called for each cell in the DataFrame\n",
    "df.style.applymap(vis_highlight_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vis_highlight_column_max(srs):\n",
    "    cmax = srs.max()\n",
    "    cmin = srs.min()\n",
    "    bg   = {0: '', 1: 'background: red', 2: 'background: green'}\n",
    "    return([bg[1*(cell==cmin) + 2*(cell==cmax)] for cell in srs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.style.apply(vis_highlight_column_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Timeseries plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "srs = pd.Series(np.random.randn(100).cumsum(), index=pd.date_range(start='31-01-2019', freq='D', periods=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "srs.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "srs.plot(figsize=(15,4), color='red', grid=(True,True));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another powerfull feature of pandas is its **rolling()** functionality. This works much like **groupby** but allows us to operate on a rolling window.<br>\n",
    "For instance to cumpute a rolling median on a window of size 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "srs.rolling(3).median().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([srs,srs.rolling(5).median()],axis=1).rename(columns={0:'raw',1:'median smoothed'}).plot(figsize=(20,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Read / Write External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I should have probably started with this! But Pandas has a powerfull set of functions to read and write data in a multitude of formats.<br>\n",
    "There is a lot to say about this, here I just want to pull out a couple of things:\n",
    "* usually data is obtained from a DB using **read_sql**\n",
    "* you can read sas data using **read_sas**\n",
    "* a very efficient / fast way to store Python objects is through **read_pickle** (or df.to_pickle to store)\n",
    "* a format that supports fast and efficient sharing between Python and R is **feather** (need to install pyarrow!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[m for m in dir(pd) if m.startswith('read_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('data/drinksbycountry.csv','r') as f: lines = f.readlines(300)\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/drinksbycountry.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.groupby('continent').beer_servings.mean().plot.bar(figsize=(15,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.set_index('country').beer_servings.sort_values(ascending=False)[:20].plot.barh(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('data/drinksbycountry.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!dir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/drinksbycountry.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_bigger = pd.read_csv('data/countrystats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df_bigger.shape)\n",
    "df_bigger.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_bigger.to_pickle('data/countrystats.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_bigger = pd.read_pickle('data/countrystats.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The performance gains are much bigger for larger datasets!! This toy example does not do it justice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pyarrow import write_feather, read_feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "write_feather(df_bigger, 'data/countrystats.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_bigger = read_feather('data/countrystats.feather', columns=None, use_threads=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
